finalHistory_peptideAmyloid.txt

# Dependencies (place in $PYTHONPATH)
# numpy, ProDy, TERMANAL (TERM Analysis and MASTER + CONFIND binaries, Ca. 2015 Gevorg Grigoryian Lab )
# Uses PS â€“ a program for the analysis of helix geometry... J. Mol. Graph. Model. (2011), doi:10.1016/j.jmgm.2011.11.004 (must compile this fortran source code)
# All other code and modules references found in Marco's ~/bin/ folder (See github repository for maintained directory)

##### Database ( constructed ) #####
##### Search database construction, (PDB subset turned into .pds files, formatted as searchable 'targets' by program MASTER )

## Remade single chain non-redundent database. from 30% culling of chains by BLASTClust on PDB. X-ray only < 2.8 A from 152901_bc_30-scPDB.txt
## Got entries_xray_res.txt pdb_seqres-byCh.txt from PDB website... look in files for what info is in there... x-ray, length, resolution
## "Summaries of PDB data" page, entries.idx & pdb_seqres.txt      http://www.rcsb.org/pdb/static.do?p=general_information/about_pdb/summaries.html

. cd ~/termanal/support.default/
> python ~/bin/masterDB_frombcscList.py entries_xray_res.txt pdb_seqres-byCh.txt 152901_bc_30-scPDB.txt  >  nr152901_bc_30-scPDB.txt

# Then download this list of PDB chains (if not too large, like ribosome cuz different file format), extract chain to new file, run createPDS to get parsed output PDB and MASTER format searchable .pds 'target' file
> python ~/bin/downloadPDBdatabaseV2_scDB.py ~/termanal/support.default/152901_bc_30-scPDB.txt /home/xray/termanal/support.default/152901_bc_30-scPDB-PRE /home/xray/termanal/support.default/152901_bc_30-scPDB /home/xray/termanal/support.default/152901_bc_30-scPDB_oPDB

# Then with some bash terminal, print the full path to each .pds into 'list.txt' inside databse directory '152901_bc_30-scPDB/'; one path per line
> for i in /home/xray/termanal/support.default/152901_bc_30-scPDB/*.pds; do echo $i >> list.txt

##### Database construction end


############### Main ################################

# comment amove command will mention (LOCAL) if done on laptop or (CLUSTER) if done on interactive node of UCSF QB3 cluster (including job submission)
# All files were passed between cluster and local through git repository (~/bin for code and ~/peptideAmyloid for working space)
# All paths should be the same after '~/', where ~/ depends on local or cluster...
# Except linux TERMANAL and database... were tarballed and transferred to 

#### Prelim file prep ####

> mkdir ~/peptideAmyloid
> mkdir ~/peptideAmyloid/parameterization

# 1) full interface file. Hard to explain, made manually. Took PDB file of OSAKA fragment of amyloid, residues 10-23 (inclusive). 
#and entended the sheet in both directions by duplicating a few chains and best aligning 2 strands to the original sheet (then hanging 3-4 strands are added).
# Renamed chains to remove overlap... save to ~/peptideAmyloid/parameterization/FullInterface.pdb 
# A in most negative Y direction, K in most positive Y

#) helix to dock, file all saved in helix_prep/ (see path below). From pdb 2ZTA aka GCN4, residues 7-24 (inclusive). Save to 18_2zta.pdb
# fit helical axis w/ PS program, Get from stdout: CA coordinates projected onto axis from output of PS (PS.linux is compiled w/ gfortran4.8).  
## or grab any segment from a CCCP coiled-coil bundle.

> mkdir ~/peptideAmyloid/parameterization/helix_prep

> ~/bin/PS.linux -i ~/peptideAmyloid/parameterization/helix_prep/18_2zta.pdb -f 7 -l 24

# Save axis coords to '~/peptideAmyloid/parameterization/helix_prep/CA_18_2zta.pdb'

# **** NOTE ***** Copy HETATM lines of PDB from C and N termini of axis to the end of 18_2zta.pdb, change to chain 'X'
# rename helical chain to A
# put the HETATM's from CA fitting from PS at bottom of file:  C-term, then N-term



## For visualization ONLY... (Local) and semi manual... make PDB file "zeroAlignment.pdb" with atoms as markers to new coordinate frame
#  For alignment of the OSAKA amyloid interface to 5 points in a new "centered" coordinate frame where helix center to be at (0,0,0)
# order of C-alpha atoms in file is same as odrder of REMARKS, the latter having pymol selection strings for residue/atom that should be aligned to this point. These atoms are hard coded into python script

> python ~/bin/quickAlignOsk.py ~/peptideAmyloid/parameterization/FullInterface.pdb ~/peptideAmyloid/parameterization/zeroAlignment.pdb 


## Note, did this same protocol for straight (w_0 = 100, curvature = inf) helix ''... 
## with 2D wall paper symmetry, aligning a helix to X-axis and setting z coords of each helical axis to 4 A above amyloid center...
## added previous and next symmetry mate, the did strucctural search of 12-center most residues on i to i+1 interface and i-1 to i itnerface. 
## with both GCN4 and ideal helix, got >250 sub-angstrom full backbone matches to the pdb files of both interfaces (2 helices with 12 residues each, axis 10 A away. )
## Hence these interfaces are generally designable    






#### OBSOLUTE, OLD SECTION
#Below section done, but needed refinement (see above section replacing this below) ###########

# (Cluster) From parameters, generate single helix model (plus repeat at one spot and repeat at the other). not submitted job, just on node
> cd parameterization
> python ~/bin/params2coords.py ~/peptideAmyloid/parameterization/params.txt ~/peptideAmyloid/parameterization/helix_prep/18_Ideal_allALA.pdb ~/peptideAmyloid/OsakaModels/ ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb

> cd ../OsakaModels


# (Cluster) Generate TERMS... submit jobs
# Write paths to all pDB to a list file. find length of list (total jobs needed)
# Alter bash submission script SGE header '#$ -t 1-XX' for this number of task (number = XX), did units of 80000

> qsub ../modelEval_qsub.sh list.txt 

# tried 900K jobs but took 2 weeks for ~20,000. so killed all early 
# gzipped and moved all output log files and .cmap files into ~/peptideAmyloid/logfile/cmpX_#date#/ (commands not shown, directory name custom for round of parameter eval)

# move score files into new directory, then summarize scores and parameters, for local analysis
> cd ~/peptideAmyloid
> for i in OsakaModels/*.sc; do mv $i scores/ ; done

> scl enable python27 'python extract_scores.py ~/peptideAmyloid/logfiles/cmp1_030415/  ~/peptideAmyloid/OsakaModels/ ~/peptideAmyloid/scoreDict.pkl ~/peptideAmyloid/scores/'

# (Local, after merge this data to git)
# plot data (pop-up window, hand scale, save) , pick designs over a threshold for each score category

> python ~/bin/desPlot.py scoreDict.pkl > rnd1_models2Design.txt 

# ~90 templates
python ~/bin/TORCH_rn1_rosiPrep.py ~/peptideAmyloid/Rnd1_models2Design.txt ~/peptideAmyloid/RND1_designTrj030515/ ~/peptideAmyloid/OsakaModels/


###################################################################



#### Prelim END  #########





######### START REAL




## (LOCAL) generate sets of parameters (6) in text file (argument 1) (one set per line, spce delimted, angles in degrees, distances in Angstroms)
## Writes many files with this same path input, but with number added before the extension. Parameters randomized 

> python ~/bin/paramsGen.py ~/peptideAmyloid/parameterization/params.txt

## Given randomized lists as mini job queues
## process each as a set of jobs: create pdb, break into fragments, determine 'design-ibility' by fragment search

> mkdir ~/peptideAmyloid/OsakaModels/
> mkdir ~/peptideAmyloid/scores_rnd1/
> mkdir ~/peptideAmyloid/logfiles/

## Before executing bash script on cluster, must go in and change the task line
#$ -t 1-N     where N = number of lines in params file **minus 1**
# can find using bash " > cat ~/peptideAmyloid/parameterization/params1.txt | wc -l "  

> qsub ~/bin/torch_evalQsub.sh ~/peptideAmyloid/parameterization/params5.txt ~/peptideAmyloid/OsakaModels/ ~/peptideAmyloid/scores_rnd1/ ~/peptideAmyloid/parameterization/helix_prep/18_Ideal_allALA.pdb ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb ~/termanal/support.default/152901_bc_30-scPDB/list.txt ~/termanal/


#### MM submitted to QB3 cluster

3/17/15: 

@ 4:47 pm JOB ID: 9367247

qsub ~/bin/torch_evalQsub.sh ~/peptideAmyloid/parameterization/params1.txt ~/peptideAmyloid/OsakaModels/ ~/peptideAmyloid/scores_rnd1/ ~/peptideAmyloid/parameterization/helix_prep/18_Ideal_allALA.pdb ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb ~/binLocal/termanal/support.default/162901_bc_30-scPDB/list.txt ~/binLocal/termanal/

@ 4:10 pm JOB ID: 9367263

qsub ~/bin/torch_evalQsub.sh ~/peptideAmyloid/parameterization/params2.txt ~/peptideAmyloid/OsakaModels/ ~/peptideAmyloid/scores_rnd1/ ~/peptideAmyloid/parameterization/helix_prep/18_Ideal_allALA.pdb ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb ~/binLocal/termanal/support.default/162901_bc_30-scPDB/list.txt ~/binLocal/termanal/

Finished overnight. dont' know what time

3/18/15 submitted same for params3.txt to params14.txt

3 9369419
4 9369420
5 9369421
6 9369422
7 9369423
8 9369424
9 9369425
10 9369426
11 9369427
12 9369428
13 9369429
14 9369431


## Lots of problems here... MASTER stdout needs to be rerouted to null, so logfiles arent huge space. Re run the whole parameter set, remake pdb files

[mmravic@iq218 peptideAmyloid]$ for i in ~/peptideAmyloid/parameterization/params*.txt; do qsub ~/bin/torch_evalQsub.sh $i ~/peptideAmyloid/rnd1OsakaModels/ ~/peptideAmyloid/rnd1_scores/ ~/peptideAmyloid/parameterization/helix_prep/18_Ideal_allALA.pdb ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb ~/binLocal/termanal/support.default/162901_bc_30-scPDB/list.txt ~/binLocal/termanal/; echo $i ; echo ;  done

Your job-array 9374426.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params10.txt

Your job-array 9374427.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params11.txt

Your job-array 9374428.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params12.txt

Your job-array 9374429.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params13.txt

Your job-array 9374430.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params14.txt

Your job-array 9374431.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params1.txt

Your job-array 9374432.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params2.txt

Your job-array 9374433.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params3.txt

Your job-array 9374434.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params4.txt

Your job-array 9374435.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params5.txt

Your job-array 9374436.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params6.txt

Your job-array 9374437.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params7.txt

Your job-array 9374438.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params8.txt

Your job-array 9374439.1-50000:1 ("torch_evalQsub.sh") has been submitted
/netapp/home/mmravic/peptideAmyloid/parameterization/params9.txt

[mmravic@iq218 peptideAmyloid]$  qdel 9374429
mmravic has deleted job 9374429

## change final job submission amount since last parameters
[mmravic@iq218 peptideAmyloid]$ vi ~/bin/torch_evalQsub.sh 

[mmravic@iq218 peptideAmyloid]$  qsub ~/bin/torch_evalQsub.sh /netapp/home/mmravic/peptideAmyloid/parameterization/params14.txt  ~/peptideAmyloid/rnd1OsakaModels/ ~/peptideAmyloid/rnd1_scores/ ~/peptideAmyloid/parameterization/helix_prep/18_Ideal_allALA.pdb ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb ~/binLocal/termanal/support.default/162901_bc_30-scPDB/list.txt ~/binLocal/termanal/
Your job-array 9374441.1-12904:1 ("torch_evalQsub.sh") has been submitted

##############  Summarize and Pull results from cluster (models and score files)

## on cluster, look into model and score files, write params and design-ibility scores (number of unique sub-threshold matches)
# depending on sign of Theta (on interval -180, 180), write to different summary file
# classify each model/parameterSet by score, as passing or not; used minimum score > 50 or average score >=80
> scl enable python27 'python ~/bin/summarize_paramsScores.py ~/peptideAmyloid/rnd1_scores/ ~/peptideAmyloid/rnd1OsakaModels/  ~/peptideAmyloid/posPaSummary.txt ~/peptideAmyloid/negPaSummary.txt'

# push these files to git, pull on local workstation
# plot histograms of 
> mkdir rnd1_analysis
> cd rnd1_analysis

# look at summary file, and sort data passing filters on scores, like min(score) >=100 (vary the python script and print lines you want based on filters)
# don't actually need to make sub directories yet, but include some somecond argument(unused)
> python ~/bin/scores_analyzePlot.py ~/peptideAmyloid/posPaSummary.txt ~/peptideAmyloid/rnd1_analysis/posTheta/

# given some subset, print info to file (parameters) to make models for ROSETTA design
> python ~/bin/scores_pickModels.py ~/peptideAmyloid/negPaSummary.txt ~/peptideAmyloid/rnd1_analysis/negTheta/ > models2designRND1.tx

## can pull models, or just make locally with parameters. 
> mkdir rnd1_design
> python ~/bin/pullModels_cluster.py ~/peptideAmyloid/models2designRND1.txt ~/peptideAmyloid/rnd1_design/ mmravic@pass2.compbio.ucsf.edu:/netapp/home/mmravic/peptideAmyloid/rnd1OsakaModels/

## prep each for rosetta... 

> python ~/bin/TORCH_rn1_rosiPrep.py ~/peptideAmyloid/models2designRND1.txt ~/peptideAmyloid/rnd1_design/

# local design of 1 (for editing/tweeking)
> python ~/bin/TORCH_rn1_design.py ~/rosetta/ ~/peptideAmyloid/rnd1_design/model_310127/model_310127.pdb  ~/peptideAmyloid/rnd1_design/designProtocol_RND1.xml  ~/peptideAmyloid/rnd1_design/resfile


# to turn into cluster job submisstion ... NOT actually designing anything from rnd1
############################

######## ROUND 2 ########### Longer helix, 21 residues
# re-wrote params2coords_rnd2.py for the longer helix
# paramsGen_rnd2.py has new focused parameters... with only negative Theta
# torch_designibility_rnd2.py should give more hits, removed C-terminal Ala-Asp backbone curve out
# Otherwise, only little things were changed, like file paths... uncluding using the 21 resi long helix


# (LOCAL)   1000692 parameters, split 50 ways (20013 per file, and dumped the remaining 43)
python ~/bin/paramsGen_rnd2.py ~/peptideAmyloid/parameterization/


# (LOCAL)
> mkdir ~/peptideAmyloid/rnd2_OsakaModels/
> mkdir ~/peptideAmyloid/rnd2_scores/
> mkdir ~/peptideAmyloid/logfiles/

## LOAD EVERYTHING TO GIT


## Before executing bash script on cluster, must go in and change the task line
#$ -t 1-N     where N = number of lines in params file **minus 1**
# can find using bash " > cat ~/peptideAmyloid/parameterization/params1.txt | wc -l "  
# lines per file: 20014


### Test (change task number to 1-5)
>  qsub ~/bin/torch_evalQsubrnd2_L.sh ~/peptideAmyloid/parameterization/params_OG.txt  ~/peptideAmyloid/rnd2_OsakaModels/ ~/peptideAmyloid/rnd2_scores/ ~/peptideAmyloid/parameterization/helix_prep/21_Ideal_allALA.pdb  ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb ~/binLocal/termanal/support.default/162901_bc_30-scPDB/list.txt ~/binLocal/termanal/


## Sub all jobs  (4/15/16)
for i in ~/peptideAmyloid/parameterization/params*_rnd2.txt; do   qsub ~/bin/torch_evalQsubrnd2_L.sh $i  ~/peptideAmyloid/rnd2_OsakaModels/ ~/peptideAmyloid/rnd2_scores/ ~/peptideAmyloid/parameterization/helix_prep/21_Ideal_allALA.pdb  ~/peptideAmyloid/parameterization/FullInterfaceCENTERED.pdb ~/binLocal/termanal/support.default/162901_bc_30-scPDB/list.txt ~/binLocal/termanal/    ; done

Your job-array 9386078.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386079.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386080.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386081.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386082.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386083.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386084.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386085.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386086.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386087.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386088.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386089.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386090.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386091.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386092.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386093.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386094.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386095.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386096.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386097.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386098.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386099.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386100.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386101.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386102.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386103.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386104.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386105.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386106.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386107.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386108.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386109.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386110.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386111.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386112.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386113.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386114.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386115.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386116.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386117.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386118.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386119.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386120.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386121.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386122.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386123.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386124.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386125.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386126.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted
Your job-array 9386127.1-20013:1 ("torch_evalQsubrnd2_L.sh") has been submitted

## This took like 8-9 days to run these million jobs
## parse all score and model files to summarize parameters in matches per fragment into big text file

## (ON CLUSTER)
> scl enable python27 'python ~/bin/summarize_paramsScores.py ~/peptideAmyloid/rnd2_scores/ ~/peptideAmyloid/rnd2_OsakaModels/  rnd2_Summary.txt '

## Then pulled all the model and score files from cluster.... and this summary file (50 MB) with an scp through ucsf pass2 nodes

## analyze summary stats of designibilitt, plot successful and failed parameters

>python ~/bin/scores_analyzePlot.py ~/peptideAmyloid/rnd2_Summary.txt ~/peptideAmyloid/rnd2_analysis/

## Pick models to design based on minimum score of 140 in all fragments. This value is hard coded, just change in the loop
> python ~/bin/scores_pickModels.py ~/peptideAmyloid/rnd2_Summary.txt ~/peptideAmyloid/rnd2_analysis/ > rnd2_models2design.txt

# there were 11 models, super quick pyton script to just grab files to move to a design directory
> python ~/bin/TORCH_rnd2_rosiPrep.py ~/peptideAmyloid/rnd2_models2design.txt ~/peptideAmyloid/rnd2_design/ ~/peptideAmyloid/rnd2_OsakaModels/

# hand copy and edit resfile... picking polar and non-polar residues







############### Main End ############################